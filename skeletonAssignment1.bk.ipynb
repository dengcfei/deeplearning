{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Assignment 1. Cat, Dog, Car or Bike?\n",
    "\n",
    "**Dataset:** You are provided with a dataset which contains more than 3000 pictures with either a cat, a dog, a motorbike or a car. The dataset has already been split in training, test and validation sets. Your task is to build and train a CNN which is able to recognize which object is depicted in the picture. To this end, you must use and change the code we presented during our tutorial on classifying cat and dog images. You should copy and unzip the dataset in your local directory (do not change the name of the directory), namely the same directory where this jupyter notebook is going to be stored. \n",
    "\n",
    "**Python and Keras version.** We recommend you to use Python 3.6 (there might be some incompatibility issues between keras and the most recent versions of Python). We also recommend to use TensorFlow 2.1.0 and Keras 2.3.1, which are the settings we used to test everything. You can find the documentation for keras at the following address https://keras.io/layers/convolutional/.\n",
    "\n",
    "**What to submit:** You should post on moodle this jupyter notebook filled will all the answers to the questions, the Python code and the plots. Do not change any part of the code that is provided to you, unless explicitly asked. You should also post on moodle the model for question 5 (name of the model \"modelQ5.h1\"). The answers to the questions should be provided below at the end of the notebook. In case your model has size larger than 100MB please provide a link to Google Drive or other storage services. **Important**: For each question you will get 0 points if the code or any of the plots are missing or the code is not correct.\n",
    "\n",
    "**GPU Farm**: You will have access to the HKU GPU farm to do this assignment. Additional info on how to use it is contained in a separate document provided with the assignement. Please use this only for questions 4 and 5.\n",
    "\n",
    "**Image Size** You should use image size 32x32 for the first three questions. You can use higher resolutions for questions 4 and 5. We kindly ask you to use your machine whenever possible, in order to avoid the GPU farm to be overwhelmed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 (CNN Architecture) \n",
    "\n",
    "Define a CNN architecture with the following layers stacked on top of each other in the following order:\n",
    "1. A convolutional layer with 32 5 × 5 filters. \n",
    "2. A max Pooling Layer with size 2 × 2.\n",
    "3. A convolutional layer with 64 5 × 5 filters. \n",
    "4. A max Pooling Layer with size 2 × 2.\n",
    "5. A convolutional layer with 64 3 × 3 filters. \n",
    "6. A max Pooling Layer with size 2 × 2.\n",
    "7. A convolutional layer with 64 3 × 3 filters. \n",
    "7. A max Pooling Layer with size 2 × 2.\n",
    "9. A dense layer with 256 units.\n",
    "10. A dense layer with k units and softmax (aka cross entropy) loss function.\n",
    "\n",
    "Use the sigmoid activation function for all layers but the last one which uses the softmax function. Use default values for the parameters which are not specified above.\n",
    "\n",
    "a) [5pts] Determine the right value for k and write the value for k you use at the end of the notebook. Write the code to solve a) in the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#documentation:https://keras.io/layers/convolutional/\n",
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "\n",
    "\n",
    "#write your own code for a) here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) [5pts] The architecture defined above cannot be built because of an error. You should fix such an error without changing the number of convolutional, pooling or dense layers, the number of filters, the size of the filters, or the number of units. Write at the end of the notebook which strategy did you use and write the code to solve b) in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentation:https://keras.io/layers/convolutional/\n",
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "\n",
    "\n",
    "#write your own code for b) here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (Training a small CNN from scratch)\n",
    "\n",
    "We are now considering a different CNN architecture specified in the code below. Fill the missing parts (there is a comment specifying which parts must be filled). After that train such a CNN using the following values for the parameters:\n",
    "\n",
    "- loss function=crossentropy;\n",
    "- optimizer RMSprop with learning rate = 0.1;\n",
    "- metrics= accuracy;\n",
    "- Batch size for the training/validation generators=20; \n",
    "- epochs=30.\n",
    "\n",
    "Train the CNN and plot both the training/validation accuracy and training/validation loss as a function of the epochs. Write the code and report the plots in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='sigmoid',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='sigmoid',padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# something is missing here \n",
    "model.add(layers.Dense(512, activation='sigmoid'))\n",
    "model.add(layers.Dense(k, activation='softmax')) #replace k with the corresponding value\n",
    "\n",
    "model.compile( #fill this part ...\n",
    "    \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'cat_dog_car_bike' # very important: do not change this!\n",
    "train_dir= os.path.join(base_dir, 'train') # very important: do not change this!\n",
    "validation_dir= os.path.join(base_dir, 'val') # very important: do not change this!\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(32, 32), # very important: do not change this!\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(32, 32), # very important: do not change this!\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) [5pts] What is the main problem for your model?\n",
    "\n",
    "1. Overfitting\n",
    "2. Underfitting\n",
    "\n",
    "Write your answer below at the end of the notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) [5pts] Without changing the learning rate, change one hyperparameter so as to improve the training error. \n",
    "\n",
    "Which hyperparameters did you change? Write your answer below at the end of the notebook. \n",
    "\n",
    "Plot both the training/validation accuracy and training/validation loss as a function of the epochs. Report the plots and the code in the cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (Optimize the learning rate) \n",
    "\n",
    "a)[10pts] Determine an interval [a,b] of possible values for the learning rate, which is “wide enough”. In particular, you should try to guarantee that your interval contains an optimal value for the learning rate. At the same time the interval that you provided should not be too wide, due to efficiency reasons. In particular, your interval [a,b] should be such that $\\frac{b}{a} \\leq 10^5$.\n",
    "\n",
    "b)[15pts] Provide a \"good\" value for the learning rate. In particular, the training error should become smaller than 0.1 within 30 epochs. \n",
    "\n",
    "Write your answers below at the end of the notebook.\n",
    "\n",
    "Using a good value for the the learning rate, plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4 (Transfer Learning) [25pts]\n",
    "\n",
    "Use the VGG16 as feature extractor with data augmentation (i.e. remove the top layer and freeze the VGGnet). Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots and the code in the cells below. You should try to achieve a validation accuracy of at least 96\\%. Report the accuracy of your model on the test set. \n",
    "\n",
    "Write the answers below at the end of the notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (Open Question) [25pts]\n",
    "\n",
    "Use any of the techniques we saw during our course so as to improve the validation accuracy of your CNN. Plot both the training/validation accuracy and training/validation as a function of the epochs. Report the plots and the code in the cells below. You should try to achieve a validation accuracy of at least 98\\% and in any case better than the validation accuracy provided in question 4. Report the accuracy of your model on the test set. \n",
    "\n",
    "Write the answers below at the end of the notebook. Your model should have max size of 300Mb. Submit your model on moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "# fill this part\n",
    "\n",
    "\n",
    "model.save('modelQ5.h1') #important do not change the name of the model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "Write your answers next to the corresponding question (same line).\n",
    "\n",
    "Question 1\n",
    "* a) What is the right value of k? \n",
    "* b) How did you fix the error in the architecture?\n",
    "\n",
    "Question 2\n",
    "* a) There was a problem of underfitting or overfitting?\n",
    "* b) Which hyperparameter did you change?\n",
    "\n",
    "Question 3\n",
    "* a) which interval for the learning rate did you consider?\n",
    "* b) which value for the learning rate did you consider?\n",
    "\n",
    "Question 4\n",
    "* a) what is the validation accuracy of your model?\n",
    "* b) what is the test accuracy of your model?\n",
    "\n",
    "Question 5\n",
    "* a) what is the validation accuracy of your model?\n",
    "* b) what is the test accuracy of your model?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
